{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"C_o0hGIAxyTl","colab_type":"code","colab":{}},"source":["# Code to read csv file into Colaboratory:\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Oc2mj6v4QoC","colab_type":"code","outputId":"341c08bc-cf42-4aad-d24c-cf77fa236e02","executionInfo":{"status":"ok","timestamp":1576176472507,"user_tz":300,"elapsed":9389,"user":{"displayName":"Ke Zhu","photoUrl":"","userId":"07864537453268672248"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import pandas as pd\n","\n","# open csv in google drive\n","link = 'https://drive.google.com/open?id=15mQ4cQiwnB4dDdSSvEtTbeZ2P-ZA2UYs'\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('train_5_now.csv')  \n","df = pd.read_csv('train_5_now.csv')\n","\n","# create dataframe from csv\n","keys = []\n","for line in df:\n","  keys.append(line)\n","print(keys)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["['text', 'label', 'hashcount', 'hashcontent', 'atcount', 'atcontent']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HzYnw3o1gSiK","colab_type":"code","outputId":"6a07dcc5-bcf2-44ee-ea51-5d51bdd01b31","executionInfo":{"status":"ok","timestamp":1576176473537,"user_tz":300,"elapsed":10407,"user":{"displayName":"Ke Zhu","photoUrl":"","userId":"07864537453268672248"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import keras\n","import numpy as np\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"IRdD6KGggZYk","colab_type":"code","colab":{}},"source":["\"\"\"\n","extract and create vocab from content\n","\"\"\"\n","def extract_vocab(contents):\n","  vocab = {}\n","  count = {}\n","  length = 0\n","  # count frequency\n","  for content in contents:\n","    # skip empty line\n","    if isinstance(content, float):\n","      continue\n","    words = content.split()\n","    for word in words:\n","      count[word] = count.get(word, 0) + 1\n","\n","  # extract word as vocab\n","  for content in contents:\n","    # skip empty line\n","    if isinstance(content, float):\n","      continue\n","    words = content.split()\n","    for word in set(words):\n","\n","      # assign ID to each words\n","      if word not in vocab and count[word] > 1:\n","        vocab[word] = len(vocab)\n","\n","    # update maximum length of the list\n","    length = max(length, len(words))\n","\n","  # words appears less than twice will be an unique label 'unk'\n","  vocab[\"unk\"] = len(vocab)\n","\n","  return count, vocab, length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xuUutO3Lgccd","colab_type":"code","colab":{}},"source":["\"\"\"\n","extract labels\n","return Y\n","\"\"\"\n","def extract_labels(df):\n","  num_classes = len(set(df[\"label\"]))\n","  y = []\n","  for label in df[\"label\"]:\n","    # skip empty line\n","    if isinstance(label, float):\n","      cur.append(0)\n","    y.append(label)\n","  # convert labels into binary style representation\n","  y = to_categorical(y, num_classes + 1, dtype='float32')\n","  return y, num_classes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"udUaP2XegfuH","colab_type":"code","colab":{}},"source":["\"\"\"\n","build X\n","0: only text content \n","1: include number of @ and #\n","2: include contents of #\n","3: include contens of @\n","4: include all contents\n","\"\"\"\n","def build_features(df, mode, vocabs):\n","  if mode < 0 or mode > 4:\n","    return []\n","\n","  # test X wont need new vocab  \n","  contents = [df[\"text\"], df[\"hashcontent\"], df[\"atcontent\"]]\n","\n","  if mode == 2:\n","    index = [0, 1]\n","  elif mode == 3:\n","    index = [0, 2]\n","  elif mode == 4:\n","    index = [0, 1, 2]\n","  else:\n","    index = [0]\n","\n","  X = np.array([])\n","  length = 0\n","  vocab_len = 0\n","  for i in index:\n","    vocab, content = vocabs[i], contents[i]\n","    vocab_len += len(vocab)\n","    length += 30\n","    cur_X = []\n","\n","    for j in range(len(content)):\n","      cur = []\n","      if isinstance(content[j], float):\n","        # empty\n","        cur.append(0)\n","      else:\n","        # reconstruct the sentence by word's ID\n","        words = content[j].split()\n","        for word in words:\n","          if word in vocab:\n","            cur.append(vocab[word])\n","          else:\n","            cur.append(vocab[\"unk\"])\n","      # update current matrix\n","      cur_X.append(cur)\n","\n","    # make all sentence respresentations the same length\n","    cur_X = np.array(pad_sequences(cur_X, 30, padding='post'))\n","\n","    # combine the matrix\n","    if len(X) == 0:\n","      X = np.array(cur_X)\n","    else:\n","      X = np.concatenate((X, cur_X), axis = 1)\n","\n","  # add sum of at and hashtag\n","  if mode == 1:\n","    cur_X = []\n","    for i in range(len(contents[0])):\n","      cur_X.append([df[\"hashcount\"][i], df[\"atcount\"][i]])\n","    X = np.concatenate((X, np.array(cur_X)), axis = 1)\n","    length += 2\n","\n","  return X, length, vocab_len"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmFDnnPl6zPc","colab_type":"code","outputId":"64cc58c8-9bb9-4457-9b43-b81462f60ae0","executionInfo":{"status":"ok","timestamp":1576176526696,"user_tz":300,"elapsed":63527,"user":{"displayName":"Ke Zhu","photoUrl":"","userId":"07864537453268672248"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["print(\"---------------------------\")\n","print(\"Extracting Features:\")\n","\n","y, num_classes = extract_labels(df)\n","\n","print(y.shape, num_classes)\n","\n","# vocabulary global\n","count1, vocab1, len1 = extract_vocab(df[\"text\"])\n","count2, vocab2, len2 = extract_vocab(df[\"hashcontent\"])\n","count3, vocab3, len3 = extract_vocab(df[\"atcontent\"])\n","vocabs = [vocab1, vocab2, vocab3]\n","\n","features = []\n","for i in range(5):\n","  X, length, vocab_len = build_features(df, i, vocabs)\n","  print(X.shape, length, vocab_len)\n","  features.append((X, length, vocab_len))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["---------------------------\n","Extracting Features:\n","(295700, 6) 5\n","(295700, 30) 30 49215\n","(295700, 32) 32 49215\n","(295700, 60) 60 77055\n","(295700, 60) 60 65080\n","(295700, 90) 90 92920\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C4mN6MzFC94X","colab_type":"code","colab":{}},"source":["\"\"\"\n","directly from https://www.kaggle.com/eray1yildiz/using-lstms-with-attention-for-emotion-recognition\n","modified:\n","  Apply Bidirectional CuDNNLSTM over embedded inputs\n","\"\"\"\n","\n","def build_lstm(length, vocab_len):\n","  # The dimension of word embeddings\n","  embedding_dim = 100\n","\n","  # Define input tensor\n","  sequence_input = keras.Input(shape=(length,), dtype='int32')\n","\n","  # Word embedding layer\n","  embedded_inputs =keras.layers.Embedding(vocab_len + 1,\n","                                        embedding_dim,\n","                                        input_length=length)(sequence_input)\n","\n","  # Apply dropout to prevent overfitting\n","  embedded_inputs = keras.layers.Dropout(0.2)(embedded_inputs)\n","\n","  # Apply Bidirectional CuDNNLSTM over embedded inputs\n","  lstm_outs = keras.layers.wrappers.Bidirectional(\n","    keras.layers.CuDNNLSTM(embedding_dim, return_sequences=True)\n","  )(embedded_inputs)\n","\n","  # Apply dropout to LSTM outputs to prevent overfitting\n","  lstm_outs = keras.layers.Dropout(0.2)(lstm_outs)\n","\n","  # Attention Mechanism - Generate attention vectors\n","  input_dim = int(lstm_outs.shape[2])\n","  permuted_inputs = keras.layers.Permute((2, 1))(lstm_outs)\n","  attention_vector = keras.layers.TimeDistributed(keras.layers.Dense(1))(lstm_outs)\n","  attention_vector = keras.layers.Reshape((length,))(attention_vector)\n","  attention_vector = keras.layers.Activation('softmax', name='attention_vec')(attention_vector)\n","  attention_output = keras.layers.Dot(axes=1)([lstm_outs, attention_vector])\n","\n","  # Last layer: fully connected with softmax activation\n","  fc = keras.layers.Dense(embedding_dim, activation='relu')(attention_output)\n","  output = keras.layers.Dense(num_classes + 1, activation='softmax')(fc)\n","\n","  # Finally building model\n","  model = keras.Model(inputs=[sequence_input], outputs=output)\n","  model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer='adam')\n","\n","  # Print model summary\n","  model.summary()\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SMnM4siug0Cf","colab_type":"code","outputId":"a9ce3f3f-a315-4635-ae98-a71f5960f789","executionInfo":{"status":"ok","timestamp":1576176528702,"user_tz":300,"elapsed":65511,"user":{"displayName":"Ke Zhu","photoUrl":"","userId":"07864537453268672248"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print(\"---------------------------\")\n","print(\"Building models:\")\n","\n","names = {0: \"only text content\" ,\n","1: \"include number of @ and #\",\n","2: \"include contents of #\",\n","3: \"include contens of @\",\n","4: \"include all contents\"}\n","\n","# build models\n","models = []\n","for i in range(5):\n","  print(names[i])\n","  models.append(build_lstm(features[i][1], features[i][2]))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["---------------------------\n","Building models:\n","only text content\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 30)           0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 30, 100)      4921600     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 30, 100)      0           embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, 30, 200)      161600      dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 30, 200)      0           bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed_1 (TimeDistrib (None, 30, 1)        201         dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 30)           0           time_distributed_1[0][0]         \n","__________________________________________________________________________________________________\n","attention_vec (Activation)      (None, 30)           0           reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","dot_1 (Dot)                     (None, 200)          0           dropout_2[0][0]                  \n","                                                                 attention_vec[0][0]              \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 100)          20100       dot_1[0][0]                      \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 6)            606         dense_2[0][0]                    \n","==================================================================================================\n","Total params: 5,104,107\n","Trainable params: 5,104,107\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","include number of @ and #\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 32)           0                                            \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 32, 100)      4921600     input_2[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 32, 100)      0           embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_2 (Bidirectional) (None, 32, 200)      161600      dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 32, 200)      0           bidirectional_2[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed_2 (TimeDistrib (None, 32, 1)        201         dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 32)           0           time_distributed_2[0][0]         \n","__________________________________________________________________________________________________\n","attention_vec (Activation)      (None, 32)           0           reshape_2[0][0]                  \n","__________________________________________________________________________________________________\n","dot_2 (Dot)                     (None, 200)          0           dropout_4[0][0]                  \n","                                                                 attention_vec[0][0]              \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 100)          20100       dot_2[0][0]                      \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 6)            606         dense_5[0][0]                    \n","==================================================================================================\n","Total params: 5,104,107\n","Trainable params: 5,104,107\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","include contents of #\n","Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 60)           0                                            \n","__________________________________________________________________________________________________\n","embedding_3 (Embedding)         (None, 60, 100)      7705600     input_3[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 60, 100)      0           embedding_3[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_3 (Bidirectional) (None, 60, 200)      161600      dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 60, 200)      0           bidirectional_3[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed_3 (TimeDistrib (None, 60, 1)        201         dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","reshape_3 (Reshape)             (None, 60)           0           time_distributed_3[0][0]         \n","__________________________________________________________________________________________________\n","attention_vec (Activation)      (None, 60)           0           reshape_3[0][0]                  \n","__________________________________________________________________________________________________\n","dot_3 (Dot)                     (None, 200)          0           dropout_6[0][0]                  \n","                                                                 attention_vec[0][0]              \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 100)          20100       dot_3[0][0]                      \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 6)            606         dense_8[0][0]                    \n","==================================================================================================\n","Total params: 7,888,107\n","Trainable params: 7,888,107\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","include contens of @\n","Model: \"model_4\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            (None, 60)           0                                            \n","__________________________________________________________________________________________________\n","embedding_4 (Embedding)         (None, 60, 100)      6508100     input_4[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 60, 100)      0           embedding_4[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_4 (Bidirectional) (None, 60, 200)      161600      dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 60, 200)      0           bidirectional_4[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed_4 (TimeDistrib (None, 60, 1)        201         dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","reshape_4 (Reshape)             (None, 60)           0           time_distributed_4[0][0]         \n","__________________________________________________________________________________________________\n","attention_vec (Activation)      (None, 60)           0           reshape_4[0][0]                  \n","__________________________________________________________________________________________________\n","dot_4 (Dot)                     (None, 200)          0           dropout_8[0][0]                  \n","                                                                 attention_vec[0][0]              \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 100)          20100       dot_4[0][0]                      \n","__________________________________________________________________________________________________\n","dense_12 (Dense)                (None, 6)            606         dense_11[0][0]                   \n","==================================================================================================\n","Total params: 6,690,607\n","Trainable params: 6,690,607\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","include all contents\n","Model: \"model_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_5 (InputLayer)            (None, 90)           0                                            \n","__________________________________________________________________________________________________\n","embedding_5 (Embedding)         (None, 90, 100)      9292100     input_5[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_9 (Dropout)             (None, 90, 100)      0           embedding_5[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_5 (Bidirectional) (None, 90, 200)      161600      dropout_9[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_10 (Dropout)            (None, 90, 200)      0           bidirectional_5[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed_5 (TimeDistrib (None, 90, 1)        201         dropout_10[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_5 (Reshape)             (None, 90)           0           time_distributed_5[0][0]         \n","__________________________________________________________________________________________________\n","attention_vec (Activation)      (None, 90)           0           reshape_5[0][0]                  \n","__________________________________________________________________________________________________\n","dot_5 (Dot)                     (None, 200)          0           dropout_10[0][0]                 \n","                                                                 attention_vec[0][0]              \n","__________________________________________________________________________________________________\n","dense_14 (Dense)                (None, 100)          20100       dot_5[0][0]                      \n","__________________________________________________________________________________________________\n","dense_15 (Dense)                (None, 6)            606         dense_14[0][0]                   \n","==================================================================================================\n","Total params: 9,474,607\n","Trainable params: 9,474,607\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-aeGnA6sDJq2","colab_type":"code","outputId":"5367260c-9cea-478f-95ff-7194def7a4a9","executionInfo":{"status":"ok","timestamp":1576177383927,"user_tz":300,"elapsed":920725,"user":{"displayName":"Ke Zhu","photoUrl":"","userId":"07864537453268672248"}},"colab":{"base_uri":"https://localhost:8080/","height":884}},"source":["print(\"---------------------------\")\n","print(\"Doing model training:\")\n","\n","# train models\n","for i in range(5):\n","  print(names[i])\n","  models[i].fit(features[i][0], y, epochs=2, batch_size=64, validation_split=0.1, shuffle=True)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["---------------------------\n","Doing model training:\n","only text content\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 266130 samples, validate on 29570 samples\n","Epoch 1/2\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","266130/266130 [==============================] - 63s 236us/step - loss: 1.0601 - acc: 0.5836 - val_loss: 1.0095 - val_acc: 0.6084\n","Epoch 2/2\n","266130/266130 [==============================] - 60s 226us/step - loss: 0.8997 - acc: 0.6545 - val_loss: 1.0007 - val_acc: 0.6131\n","include number of @ and #\n","Train on 266130 samples, validate on 29570 samples\n","Epoch 1/2\n","266130/266130 [==============================] - 62s 233us/step - loss: 1.0516 - acc: 0.5878 - val_loss: 0.9978 - val_acc: 0.6123\n","Epoch 2/2\n","266130/266130 [==============================] - 61s 230us/step - loss: 0.8952 - acc: 0.6561 - val_loss: 1.0048 - val_acc: 0.6102\n","include contents of #\n","Train on 266130 samples, validate on 29570 samples\n","Epoch 1/2\n","266130/266130 [==============================] - 93s 351us/step - loss: 1.0505 - acc: 0.5853 - val_loss: 1.0013 - val_acc: 0.6126\n","Epoch 2/2\n","266130/266130 [==============================] - 92s 346us/step - loss: 0.8938 - acc: 0.6563 - val_loss: 1.0008 - val_acc: 0.6112\n","include contens of @\n","Train on 266130 samples, validate on 29570 samples\n","Epoch 1/2\n","266130/266130 [==============================] - 89s 333us/step - loss: 1.0577 - acc: 0.5824 - val_loss: 1.0016 - val_acc: 0.6116\n","Epoch 2/2\n","266130/266130 [==============================] - 87s 328us/step - loss: 0.8966 - acc: 0.6555 - val_loss: 0.9984 - val_acc: 0.6126\n","include all contents\n","Train on 266130 samples, validate on 29570 samples\n","Epoch 1/2\n","266130/266130 [==============================] - 123s 461us/step - loss: 1.0499 - acc: 0.5871 - val_loss: 0.9999 - val_acc: 0.6111\n","Epoch 2/2\n","266130/266130 [==============================] - 121s 456us/step - loss: 0.8918 - acc: 0.6577 - val_loss: 1.0007 - val_acc: 0.6147\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T1ug224DDOkd","colab_type":"code","outputId":"b9e26b45-f0d8-47d1-875a-5ec20ba35f38","executionInfo":{"status":"ok","timestamp":1576177388284,"user_tz":300,"elapsed":925071,"user":{"displayName":"Ke Zhu","photoUrl":"","userId":"07864537453268672248"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["import numpy as np\n","\n","print(\"---------------------------\")\n","print(\"Doing test:\")\n","\n","# read test\n","link = 'https://drive.google.com/open?id=1HSzZBgvWtD-7sNLtdJY5877SQGJakwm0'\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('test_5_now.csv')  \n","test = pd.read_csv('test_5_now.csv')\n","\n","# get evaluation report\n","test_y, num_classes = extract_labels(test)\n","for i in range(5):\n","  print(names[i])\n","  test_X, length, vocab_len = build_features(test, i, vocabs)\n","  res = models[i].evaluate(test_X, test_y, verbose=1)\n","  print(\"Loss:\", res[0])\n","  print(\"Accuracy\", res[1])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["---------------------------\n","Doing test:\n","only text content\n","4813/4813 [==============================] - 0s 87us/step\n","Loss: 1.0312710192999572\n","Accuracy 0.6044047371763562\n","include number of @ and #\n","4813/4813 [==============================] - 0s 87us/step\n","Loss: 1.0342411415234638\n","Accuracy 0.5992104717012307\n","include contents of #\n","4813/4813 [==============================] - 1s 123us/step\n","Loss: 1.032220564053506\n","Accuracy 0.5975483067437415\n","include contens of @\n","4813/4813 [==============================] - 1s 121us/step\n","Loss: 1.0244034139500222\n","Accuracy 0.6081446084019153\n","include all contents\n","4813/4813 [==============================] - 1s 160us/step\n","Loss: 1.0292769146267748\n","Accuracy 0.6083523789798052\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O8z-H9M05NmF","colab_type":"code","outputId":"4e8601d6-452d-4e50-f2d3-f0789456f1bb","executionInfo":{"status":"ok","timestamp":1576177392584,"user_tz":300,"elapsed":929362,"user":{"displayName":"Ke Zhu","photoUrl":"","userId":"07864537453268672248"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["print(\"---------------------------\")\n","print(\"Doing validation:\")\n","\n","# read validation data\n","link = 'https://drive.google.com/open?id=1N-LnZZa1rFD-yAI3lNzdJshHKK40OgPp'\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('validation_5_now.csv')  \n","valid = pd.read_csv('validation_5_now.csv')\n","\n","# get evaluation report\n","valid_y, num_classes = extract_labels(valid)\n","for i in range(5):\n","  print(names[i])\n","  valid_X, length, vocab_len = build_features(valid, i, vocabs)\n","  res = models[i].evaluate(valid_X, valid_y, verbose=1)\n","  print(\"Loss:\", res[0])\n","  print(\"Accuracy\", res[1])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["---------------------------\n","Doing validation:\n","only text content\n","4793/4793 [==============================] - 0s 88us/step\n","Loss: 1.0085597610811885\n","Accuracy 0.6106822450897675\n","include number of @ and #\n","4793/4793 [==============================] - 0s 85us/step\n","Loss: 1.0155119152773453\n","Accuracy 0.6056749425749178\n","include contents of #\n","4793/4793 [==============================] - 1s 118us/step\n","Loss: 1.0264122686952184\n","Accuracy 0.6019194659499318\n","include contens of @\n","4793/4793 [==============================] - 1s 121us/step\n","Loss: 1.0140224861471931\n","Accuracy 0.6094304194237478\n","include all contents\n","4793/4793 [==============================] - 1s 160us/step\n","Loss: 1.0132237828377266\n","Accuracy 0.6106822448037448\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Jm_OlrAdpWs","colab_type":"code","colab":{}},"source":["\"\"\"\n","predict emoji labels\n","\"\"\"\n","\n","def predict_lstm(sentences, vocab, model):\n","\n","  X = []\n","  for i in range(len(sentences)):\n","    cur = []\n","    if isinstance(sentences[i], float):\n","      # empty\n","      cur.append(0)\n","    else:\n","      # reconstruct the sentence by word's ID\n","      words = sentences[i].split()\n","      for word in words:\n","        if word in vocab:\n","          cur.append(vocab[word])\n","        else:\n","          cur.append(vocab[\"unk\"])\n","    # update current matrix\n","    X.append(cur)\n","\n","  # make all sentence respresentations the same length\n","  X = np.array(pad_sequences(X, 30, padding='post'))\n","\n","  label_probs = model.predict(X)\n","  labels = np.argmax(label_probs, axis=1)\n","  return labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qvb7k7hKdtNT","colab_type":"code","outputId":"ca877707-91ff-421e-b6ba-d52a324388e2","executionInfo":{"status":"ok","timestamp":1576177394091,"user_tz":300,"elapsed":930846,"user":{"displayName":"Ke Zhu","photoUrl":"","userId":"07864537453268672248"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\"\"\"\n","human label test\n","\"\"\"\n","\n","print(\"---------------------------\")\n","print(\"Doing human label test:\")\n","\n","link = 'https://drive.google.com/open?id=1xNcZPUOaqMYlZQt1T_5axCfxW87YC3rG'\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('human_test.txt')  \n","f = open('human_test.txt')\n","\n","sentences = []\n","for line in f:\n","  sentences.append(line)\n","\n","labels = predict_lstm(sentences, vocabs[0], models[0])\n","for label in labels:\n","  print(label)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["---------------------------\n","Doing human label test:\n","1\n","1\n","1\n","2\n","1\n","3\n","1\n","1\n","1\n","2\n","2\n","4\n","3\n","4\n","3\n","3\n","4\n","1\n","1\n","1\n","2\n","1\n","3\n","2\n","4\n","2\n","3\n","3\n","3\n","1\n","3\n","1\n","3\n","2\n","5\n","3\n","3\n","2\n","3\n","2\n","1\n","2\n","4\n","1\n","1\n","1\n","1\n","1\n","3\n","3\n","2\n","3\n","1\n","2\n","3\n","3\n","3\n","1\n","2\n","1\n","1\n","5\n","3\n","1\n","1\n","3\n","3\n","2\n","4\n","3\n","1\n","1\n","3\n","1\n","3\n","3\n","3\n","1\n","1\n","1\n","3\n","2\n","3\n","3\n","1\n","2\n","4\n","2\n","1\n","3\n","3\n","2\n","3\n","5\n","3\n","3\n","3\n","2\n","4\n","2\n","3\n","3\n","3\n","3\n","1\n","3\n","1\n","1\n","3\n","1\n","1\n","3\n","3\n","4\n","4\n","5\n","1\n","2\n","1\n","3\n","1\n","3\n","4\n","3\n","2\n","2\n","3\n","1\n","1\n","3\n","1\n","5\n","3\n","1\n","3\n","3\n","1\n","2\n","1\n","3\n","3\n","3\n","3\n","3\n","3\n","2\n","1\n","1\n","3\n","1\n","1\n","2\n","3\n","3\n","5\n","2\n","3\n","3\n","1\n","1\n","4\n","4\n","3\n","3\n","1\n","3\n","3\n","1\n","3\n","3\n","1\n","1\n","2\n","3\n","4\n","3\n","2\n","3\n","2\n","1\n","1\n","1\n","3\n","3\n","3\n","2\n","3\n","3\n","1\n","1\n","1\n","1\n","3\n","1\n","4\n","1\n","1\n","2\n","3\n","1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S4rEQDsl6Dxi","colab_type":"code","outputId":"8992f0f3-1acd-458a-d83b-3b3b5a4cee5d","executionInfo":{"status":"ok","timestamp":1576179567163,"user_tz":300,"elapsed":965150,"user":{"displayName":"Ke Zhu","photoUrl":"","userId":"07864537453268672248"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\"\"\"\n","train and predict 20 emoji dataset\n","\"\"\"\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","print(\"---------------------------\")\n","print(\"For 20 emoji dataset:\")\n","# open csv in google drive\n","link = 'https://drive.google.com/open?id=1zjypXqXd9at3x-4ZxLTk4oE1U5D0OqHt'\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('train_20_now.csv')  \n","df = pd.read_csv('train_20_now.csv')\n","\n","# create dataframe from csv\n","keys = []\n","for line in df:\n","  keys.append(line)\n","print(keys)\n","y, num_classes = extract_labels(df)\n","print(y.shape, num_classes)\n","\n","# vocabulary global\n","count1, vocab1, len1 = extract_vocab(df[\"text\"])\n","count2, vocab2, len2 = extract_vocab(df[\"hashcontent\"])\n","count3, vocab3, len3 = extract_vocab(df[\"atcontent\"])\n","vocabs = [vocab1, vocab2, vocab3]\n","\n","# extract features\n","print(\"---------------------------\")\n","print(\"Extracting features:\")\n","features = []\n","for i in range(5):\n","  X, length, vocab_len = build_features(df, i, vocabs)\n","  print(X.shape, length, vocab_len)\n","  features.append((X, length, vocab_len))\n","\n","names = {0: \"only text content\" ,\n","1: \"include number of @ and #\",\n","2: \"include contents of #\",\n","3: \"include contens of @\",\n","4: \"include all contents\"}\n","\n","# build models\n","print(\"---------------------------\")\n","print(\"Building models:\")\n","models = []\n","for i in range(5):\n","  print(names[i])\n","  models.append(build_lstm(features[i][1], features[i][2]))\n","\n","# train models\n","print(\"---------------------------\")\n","print(\"Training models:\")\n","for i in range(5):\n","  print(names[i])\n","  models[i].fit(features[i][0], y, epochs=2, batch_size=64, validation_split=0.1, shuffle=True)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["---------------------------\n","For 20 emoji dataset:\n","['text', 'label', 'hashcount', 'hashcontent', 'atcount', 'atcontent']\n","(580271, 21) 20\n","---------------------------\n","Extracting features:\n","(580271, 30) 30 78851\n","(580271, 32) 32 78851\n","(580271, 60) 60 126174\n","(580271, 60) 60 103136\n","(580271, 90) 90 150459\n","---------------------------\n","Building models:\n","only text content\n","Model: \"model_6\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_6 (InputLayer)            (None, 30)           0                                            \n","__________________________________________________________________________________________________\n","embedding_6 (Embedding)         (None, 30, 100)      7885200     input_6[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_11 (Dropout)            (None, 30, 100)      0           embedding_6[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_6 (Bidirectional) (None, 30, 200)      161600      dropout_11[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 30, 200)      0           bidirectional_6[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed_6 (TimeDistrib (None, 30, 1)        201         dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_6 (Reshape)             (None, 30)           0           time_distributed_6[0][0]         \n","__________________________________________________________________________________________________\n","attention_vec (Activation)      (None, 30)           0           reshape_6[0][0]                  \n","__________________________________________________________________________________________________\n","dot_6 (Dot)                     (None, 200)          0           dropout_12[0][0]                 \n","                                                                 attention_vec[0][0]              \n","__________________________________________________________________________________________________\n","dense_17 (Dense)                (None, 100)          20100       dot_6[0][0]                      \n","__________________________________________________________________________________________________\n","dense_18 (Dense)                (None, 21)           2121        dense_17[0][0]                   \n","==================================================================================================\n","Total params: 8,069,222\n","Trainable params: 8,069,222\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","include number of @ and #\n","Model: \"model_7\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_7 (InputLayer)            (None, 32)           0                                            \n","__________________________________________________________________________________________________\n","embedding_7 (Embedding)         (None, 32, 100)      7885200     input_7[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 32, 100)      0           embedding_7[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_7 (Bidirectional) (None, 32, 200)      161600      dropout_13[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_14 (Dropout)            (None, 32, 200)      0           bidirectional_7[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed_7 (TimeDistrib (None, 32, 1)        201         dropout_14[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_7 (Reshape)             (None, 32)           0           time_distributed_7[0][0]         \n","__________________________________________________________________________________________________\n","attention_vec (Activation)      (None, 32)           0           reshape_7[0][0]                  \n","__________________________________________________________________________________________________\n","dot_7 (Dot)                     (None, 200)          0           dropout_14[0][0]                 \n","                                                                 attention_vec[0][0]              \n","__________________________________________________________________________________________________\n","dense_20 (Dense)                (None, 100)          20100       dot_7[0][0]                      \n","__________________________________________________________________________________________________\n","dense_21 (Dense)                (None, 21)           2121        dense_20[0][0]                   \n","==================================================================================================\n","Total params: 8,069,222\n","Trainable params: 8,069,222\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","include contents of #\n","Model: \"model_8\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_8 (InputLayer)            (None, 60)           0                                            \n","__________________________________________________________________________________________________\n","embedding_8 (Embedding)         (None, 60, 100)      12617500    input_8[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_15 (Dropout)            (None, 60, 100)      0           embedding_8[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_8 (Bidirectional) (None, 60, 200)      161600      dropout_15[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_16 (Dropout)            (None, 60, 200)      0           bidirectional_8[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed_8 (TimeDistrib (None, 60, 1)        201         dropout_16[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_8 (Reshape)             (None, 60)           0           time_distributed_8[0][0]         \n","__________________________________________________________________________________________________\n","attention_vec (Activation)      (None, 60)           0           reshape_8[0][0]                  \n","__________________________________________________________________________________________________\n","dot_8 (Dot)                     (None, 200)          0           dropout_16[0][0]                 \n","                                                                 attention_vec[0][0]              \n","__________________________________________________________________________________________________\n","dense_23 (Dense)                (None, 100)          20100       dot_8[0][0]                      \n","__________________________________________________________________________________________________\n","dense_24 (Dense)                (None, 21)           2121        dense_23[0][0]                   \n","==================================================================================================\n","Total params: 12,801,522\n","Trainable params: 12,801,522\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","include contens of @\n","Model: \"model_9\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_9 (InputLayer)            (None, 60)           0                                            \n","__________________________________________________________________________________________________\n","embedding_9 (Embedding)         (None, 60, 100)      10313700    input_9[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_17 (Dropout)            (None, 60, 100)      0           embedding_9[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_9 (Bidirectional) (None, 60, 200)      161600      dropout_17[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_18 (Dropout)            (None, 60, 200)      0           bidirectional_9[0][0]            \n","__________________________________________________________________________________________________\n","time_distributed_9 (TimeDistrib (None, 60, 1)        201         dropout_18[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_9 (Reshape)             (None, 60)           0           time_distributed_9[0][0]         \n","__________________________________________________________________________________________________\n","attention_vec (Activation)      (None, 60)           0           reshape_9[0][0]                  \n","__________________________________________________________________________________________________\n","dot_9 (Dot)                     (None, 200)          0           dropout_18[0][0]                 \n","                                                                 attention_vec[0][0]              \n","__________________________________________________________________________________________________\n","dense_26 (Dense)                (None, 100)          20100       dot_9[0][0]                      \n","__________________________________________________________________________________________________\n","dense_27 (Dense)                (None, 21)           2121        dense_26[0][0]                   \n","==================================================================================================\n","Total params: 10,497,722\n","Trainable params: 10,497,722\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","include all contents\n","Model: \"model_10\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_10 (InputLayer)           (None, 90)           0                                            \n","__________________________________________________________________________________________________\n","embedding_10 (Embedding)        (None, 90, 100)      15046000    input_10[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_19 (Dropout)            (None, 90, 100)      0           embedding_10[0][0]               \n","__________________________________________________________________________________________________\n","bidirectional_10 (Bidirectional (None, 90, 200)      161600      dropout_19[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_20 (Dropout)            (None, 90, 200)      0           bidirectional_10[0][0]           \n","__________________________________________________________________________________________________\n","time_distributed_10 (TimeDistri (None, 90, 1)        201         dropout_20[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_10 (Reshape)            (None, 90)           0           time_distributed_10[0][0]        \n","__________________________________________________________________________________________________\n","attention_vec (Activation)      (None, 90)           0           reshape_10[0][0]                 \n","__________________________________________________________________________________________________\n","dot_10 (Dot)                    (None, 200)          0           dropout_20[0][0]                 \n","                                                                 attention_vec[0][0]              \n","__________________________________________________________________________________________________\n","dense_29 (Dense)                (None, 100)          20100       dot_10[0][0]                     \n","__________________________________________________________________________________________________\n","dense_30 (Dense)                (None, 21)           2121        dense_29[0][0]                   \n","==================================================================================================\n","Total params: 15,230,022\n","Trainable params: 15,230,022\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","---------------------------\n","Training models:\n","only text content\n","Train on 522243 samples, validate on 58028 samples\n","Epoch 1/2\n","522243/522243 [==============================] - 148s 284us/step - loss: 2.2176 - acc: 0.3493 - val_loss: 2.1158 - val_acc: 0.3686\n","Epoch 2/2\n","522243/522243 [==============================] - 147s 281us/step - loss: 1.9562 - acc: 0.4168 - val_loss: 2.1019 - val_acc: 0.3758\n","include number of @ and #\n","Train on 522243 samples, validate on 58028 samples\n","Epoch 1/2\n","522243/522243 [==============================] - 149s 286us/step - loss: 2.2048 - acc: 0.3515 - val_loss: 2.1004 - val_acc: 0.3742\n","Epoch 2/2\n","522243/522243 [==============================] - 147s 282us/step - loss: 1.9424 - acc: 0.4198 - val_loss: 2.0895 - val_acc: 0.3772\n","include contents of #\n","Train on 522243 samples, validate on 58028 samples\n","Epoch 1/2\n","522243/522243 [==============================] - 230s 440us/step - loss: 2.2162 - acc: 0.3495 - val_loss: 2.1082 - val_acc: 0.3704\n","Epoch 2/2\n","522243/522243 [==============================] - 228s 436us/step - loss: 1.9555 - acc: 0.4173 - val_loss: 2.1023 - val_acc: 0.3756\n","include contens of @\n","Train on 522243 samples, validate on 58028 samples\n","Epoch 1/2\n","522243/522243 [==============================] - 213s 408us/step - loss: 2.2059 - acc: 0.3521 - val_loss: 2.1141 - val_acc: 0.3695\n","Epoch 2/2\n","522243/522243 [==============================] - 210s 403us/step - loss: 1.9457 - acc: 0.4193 - val_loss: 2.1104 - val_acc: 0.3724\n","include all contents\n","Train on 522243 samples, validate on 58028 samples\n","Epoch 1/2\n","522243/522243 [==============================] - 296s 567us/step - loss: 2.2116 - acc: 0.3511 - val_loss: 2.1086 - val_acc: 0.3712\n","Epoch 2/2\n","522243/522243 [==============================] - 293s 561us/step - loss: 1.9499 - acc: 0.4182 - val_loss: 2.1075 - val_acc: 0.3718\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y77v5GKXa4j3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"cfd793ab-01f0-4294-f775-27461e5fd2a1","executionInfo":{"status":"ok","timestamp":1576179571153,"user_tz":300,"elapsed":4007,"user":{"displayName":"Ke Zhu","photoUrl":"","userId":"07864537453268672248"}}},"source":["# read test\n","print(\"---------------------------\")\n","print(\"Doing test:\")\n","link = 'https://drive.google.com/open?id=1XQ5IyiEJFdJWmMKvlpJsNlmE_92-i4Ce'\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('test_20_now.csv')  \n","test = pd.read_csv('test_20_now.csv')\n","\n","# get evaluation report\n","test_y, num_classes = extract_labels(test)\n","for i in range(5):\n","  print(names[i])\n","  test_X, length, vocab_len = build_features(test, i, vocabs)\n","  res = models[i].evaluate(test_X, test_y, verbose=1)\n","  print(\"Loss:\", res[0])\n","  print(\"Accuracy\", res[1])"],"execution_count":17,"outputs":[{"output_type":"stream","text":["---------------------------\n","Doing test:\n","only text content\n","4370/4370 [==============================] - 0s 94us/step\n","Loss: 2.0484702620953663\n","Accuracy 0.38009153323533607\n","include number of @ and #\n","4370/4370 [==============================] - 0s 91us/step\n","Loss: 2.035998703413206\n","Accuracy 0.3842105263703475\n","include contents of #\n","4370/4370 [==============================] - 1s 127us/step\n","Loss: 2.04173323742585\n","Accuracy 0.37826086957203714\n","include contens of @\n","4370/4370 [==============================] - 1s 126us/step\n","Loss: 2.053848368297725\n","Accuracy 0.3828375286109387\n","include all contents\n","4370/4370 [==============================] - 1s 165us/step\n","Loss: 2.056784960989003\n","Accuracy 0.37871853551002604\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eA-FRqhha4xX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"6d0ab7b1-9f9b-441b-b513-4d54d05e9643","executionInfo":{"status":"ok","timestamp":1576179575056,"user_tz":300,"elapsed":3916,"user":{"displayName":"Ke Zhu","photoUrl":"","userId":"07864537453268672248"}}},"source":["# read validation data\n","print(\"---------------------------\")\n","print(\"Doing validation:\")\n","link = 'https://drive.google.com/open?id=1NPkUvXqKPuSROYJwG1daSBFnIaUt_QZB'\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('validation_20_now.csv')  \n","valid = pd.read_csv('validation_20_now.csv')\n","\n","# get evaluation report\n","valid_y, num_classes = extract_labels(valid)\n","for i in range(5):\n","  print(names[i])\n","  valid_X, length, vocab_len = build_features(valid, i, vocabs)\n","  res = models[i].evaluate(valid_X, valid_y, verbose=1)\n","  print(\"Loss:\", res[0])\n","  print(\"Accuracy\", res[1])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["---------------------------\n","Doing validation:\n","only text content\n","4359/4359 [==============================] - 0s 91us/step\n","Loss: 2.0984813579590833\n","Accuracy 0.37003899978084503\n","include number of @ and #\n","4359/4359 [==============================] - 0s 93us/step\n","Loss: 2.0956390924644075\n","Accuracy 0.3695801789503793\n","include contents of #\n","4359/4359 [==============================] - 1s 125us/step\n","Loss: 2.107369819401765\n","Accuracy 0.36568020189142086\n","include contens of @\n","4359/4359 [==============================] - 1s 125us/step\n","Loss: 2.1049057684187553\n","Accuracy 0.367056664382818\n","include all contents\n","4359/4359 [==============================] - 1s 166us/step\n","Loss: 2.1027862863765994\n","Accuracy 0.37279192476363926\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mNgz-RDUa5Fo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b878ca99-b5dd-4c6b-f1b3-f95637a50c6c","executionInfo":{"status":"ok","timestamp":1576179576708,"user_tz":300,"elapsed":1658,"user":{"displayName":"Ke Zhu","photoUrl":"","userId":"07864537453268672248"}}},"source":["# human label test\n","print(\"---------------------------\")\n","print(\"Doing human label test:\")\n","link = 'https://drive.google.com/open?id=1xNcZPUOaqMYlZQt1T_5axCfxW87YC3rG'\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('human_test.txt')  \n","f = open('human_test.txt')\n","\n","sentences = []\n","for line in f:\n","  sentences.append(line)\n","labels = predict_lstm(sentences, vocabs[0], models[0])\n","for label in labels:\n","  print(label)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["---------------------------\n","Doing human label test:\n","1\n","1\n","1\n","2\n","1\n","3\n","1\n","1\n","1\n","1\n","1\n","1\n","3\n","4\n","3\n","1\n","4\n","1\n","1\n","1\n","2\n","3\n","3\n","2\n","1\n","3\n","3\n","3\n","3\n","1\n","3\n","1\n","3\n","1\n","5\n","3\n","1\n","3\n","3\n","6\n","1\n","2\n","16\n","1\n","1\n","1\n","1\n","1\n","3\n","3\n","8\n","5\n","5\n","2\n","3\n","3\n","3\n","1\n","3\n","1\n","1\n","5\n","14\n","1\n","1\n","1\n","3\n","3\n","4\n","3\n","1\n","1\n","3\n","5\n","3\n","1\n","1\n","1\n","1\n","5\n","3\n","3\n","3\n","3\n","1\n","3\n","4\n","3\n","1\n","1\n","3\n","2\n","3\n","5\n","3\n","3\n","3\n","1\n","19\n","3\n","3\n","3\n","3\n","3\n","1\n","3\n","3\n","1\n","3\n","1\n","1\n","3\n","3\n","5\n","3\n","5\n","1\n","3\n","1\n","3\n","1\n","3\n","4\n","3\n","3\n","2\n","1\n","1\n","1\n","3\n","1\n","5\n","3\n","1\n","14\n","3\n","1\n","1\n","1\n","3\n","3\n","3\n","3\n","3\n","3\n","1\n","1\n","1\n","3\n","1\n","5\n","3\n","1\n","2\n","1\n","1\n","3\n","3\n","1\n","1\n","4\n","4\n","3\n","14\n","1\n","3\n","14\n","1\n","3\n","3\n","1\n","1\n","2\n","3\n","4\n","3\n","3\n","3\n","3\n","1\n","1\n","1\n","6\n","3\n","3\n","1\n","3\n","3\n","1\n","1\n","1\n","8\n","5\n","1\n","4\n","1\n","1\n","3\n","2\n","1\n"],"name":"stdout"}]}]}